Below are complete example snippets for each of the key modules. You can drop these into your project under the paths shown in the project‑structure earlier.

---

## `src/index.html`

```html
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Stretchy Face</title>
  <link rel="stylesheet" href="./styles.css" />
</head>
<body>
  <!-- Upload / Drag‑Drop Container -->
  <div id="upload-container">
    <input type="file" id="upload" accept="image/*" />
  </div>

  <!-- Cropper UI (hidden until after upload) -->
  <div id="cropper-container" class="hidden">
    <img id="cropper-image" src="" alt="Crop your photo" />
    <button id="use-crop">Use This Crop</button>
    <button id="reupload">Re‑upload Photo</button>
  </div>

  <!-- Three.js Canvas -->
  <canvas id="c"></canvas>

  <script type="module" src="./main.js"></script>
</body>
</html>
```

---

## `src/styles.css`

```css
/* Make body & html fill the screen */
html, body {
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  overflow: hidden;
}

/* Full‑screen canvas */
#c {
  display: block;
  width: 100vw;
  height: 100vh;
}

/* Center upload container */
#upload-container {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
}

/* Cropper UI */
#cropper-container {
  position: absolute;
  top: 10%;
  left: 50%;
  transform: translateX(-50%);
  background: rgba(255,255,255,0.9);
  padding: 1rem;
  border-radius: 8px;
}

.hidden {
  display: none;
}
```

---

## `src/main.js`

```js
import * as THREE from 'three';
import { detectFace } from './utils/faceDetection.js';
import { showCropper, hideCropper } from './ui/cropperUI.js';
import { createMesh, stretchRegion, updateSprings, resetMesh } from './utils/meshDeformer.js';
import { initControls } from './ui/controlsUI.js';
import { captureCanvas } from './utils/share.js';

let renderer, scene, camera, mesh;
let lastTime = performance.now();

async function init() {
  // 1. Let user upload & crop
  const img = await showCropper();       // returns HTMLImageElement or Canvas
  hideCropper();

  // 2. Detect face & crop
  let bbox;
  try {
    bbox = await detectFace(img);
  } catch {
    bbox = { x:0, y:0, width: img.width, height: img.height };
  }
  const cropped = document.createElement('canvas');
  cropped.width = bbox.width;
  cropped.height = bbox.height;
  const ctx = cropped.getContext('2d');
  ctx.drawImage(img, bbox.x, bbox.y, bbox.width, bbox.height, 0, 0, bbox.width, bbox.height);

  // 3. Three.js setup
  renderer = new THREE.WebGLRenderer({ canvas: document.getElementById('c'), antialias:true });
  renderer.setSize(window.innerWidth, window.innerHeight);

  scene  = new THREE.Scene();
  camera = new THREE.PerspectiveCamera(50, window.innerWidth/window.innerHeight, 0.1, 1000);
  camera.position.set(0,0,3);
  scene.add(new THREE.AmbientLight(0xffffff, 1));

  // 4. Create deformable mesh
  mesh = createMesh(new THREE.CanvasTexture(cropped), 2, 2 * (bbox.height/bbox.width), 100);
  scene.add(mesh);

  // 5. Hook interactions
  let isDown = false, prevPt = new THREE.Vector3();
  const ray = new THREE.Raycaster(), ptr = new THREE.Vector2();

  function getHit(event) {
    const rect = renderer.domElement.getBoundingClientRect();
    ptr.x = ((event.clientX - rect.left)/rect.width)*2 -1;
    ptr.y = -((event.clientY - rect.top)/rect.height)*2 +1;
    ray.setFromCamera(ptr, camera);
    const hits = ray.intersectObject(mesh);
    return hits[0] ? hits[0].point : null;
  }

  renderer.domElement.addEventListener('pointerdown', e => {
    isDown = true;
    const p = getHit(e);
    if (p) prevPt.copy(p);
  });
  renderer.domElement.addEventListener('pointermove', e => {
    if (!isDown) return;
    const p = getHit(e);
    if (p) {
      stretchRegion(prevPt, p);
      prevPt.copy(p);
    }
  });
  renderer.domElement.addEventListener('pointerup', () => isDown = false);

  // 6. GUI controls
  initControls({
    onReset: () => resetMesh(),
    onDownload: () => captureCanvas(renderer.domElement),
    onParamsChange: ({ radius, strength, stiffness, damping }) => {
      mesh.userData.radius   = radius;
      mesh.userData.strength = strength;
      mesh.userData.kStiff   = stiffness;
      mesh.userData.damping  = damping;
    }
  });

  // 7. Animation loop
  function animate(now) {
    const dt = (now - lastTime) / 1000;
    updateSprings(dt);
    renderer.render(scene, camera);
    lastTime = now;
    requestAnimationFrame(animate);
  }
  requestAnimationFrame(animate);
}

init();
```

---

## `src/utils/faceDetection.js`

```js
import * as facemesh from '@tensorflow-models/facemesh';
import '@tensorflow/tfjs-backend-webgl';

let model = null;

/**
 * Returns a bbox {x,y,width,height} around the first detected face
 * or rejects if none found.
 */
export async function detectFace(imageElementOrCanvas) {
  if (!model) model = await facemesh.load();
  const predictions = await model.estimateFaces(imageElementOrCanvas);
  if (!predictions.length) {
    throw new Error('No face detected');
  }
  const { topLeft, bottomRight } = predictions[0];
  const [x1, y1] = topLeft;
  const [x2, y2] = bottomRight;
  return { x: x1, y: y1, width: x2-x1, height: y2-y1 };
}
```

---

## `src/ui/cropperUI.js`

```js
import Cropper from 'cropperjs';
import 'cropperjs/dist/cropper.css';

const uploadEl = document.getElementById('upload');
const cropperContainer = document.getElementById('cropper-container');
const cropperImage     = document.getElementById('cropper-image');
const useBtn           = document.getElementById('use-crop');
const reupBtn          = document.getElementById('reupload');

let resolveCrop;
let cropper;

/**
 * Show file picker + Cropper.js. Returns a Promise<HTMLCanvasElement>
 */
export function showCropper() {
  return new Promise(res => {
    resolveCrop = res;
    uploadEl.onchange = () => {
      const file = uploadEl.files[0];
      const url  = URL.createObjectURL(file);
      cropperImage.src = url;
      cropperContainer.classList.remove('hidden');
      cropper = new Cropper(cropperImage, { viewMode: 1, autoCropArea: 1 });
    };
    uploadEl.click();
  });
}

useBtn.addEventListener('click', () => {
  const canvas = cropper.getCroppedCanvas();
  cropper.destroy();
  cropperContainer.classList.add('hidden');
  resolveCrop(canvas);
});

reupBtn.addEventListener('click', () => {
  cropper.destroy();
  cropperContainer.classList.add('hidden');
  showCropper().then(resolveCrop);
});

export function hideCropper() {
  cropperContainer.classList.add('hidden');
}
```

---

## `src/utils/meshDeformer.js`

```js
import * as THREE from 'three';

let positions, originalPos, velocities;
let vertexCount, geo;

/**
 * Creates a subdivided plane mesh, sets up userData for springs.
 */
export function createMesh(texture, width, height, segments) {
  geo = new THREE.PlaneGeometry(width, height, segments, segments);
  vertexCount  = geo.attributes.position.count;
  positions    = geo.attributes.position;
  originalPos  = positions.array.slice();
  velocities   = new Float32Array(vertexCount*3).fill(0);

  const mat = new THREE.MeshBasicMaterial({ map: texture });
  const mesh = new THREE.Mesh(geo, mat);

  // default spring params & brush
  mesh.userData.radius   = 0.3;
  mesh.userData.strength = 1.0;
  mesh.userData.kStiff   = 8;
  mesh.userData.damping  = 4;

  return mesh;
}

/**
 * Smear vertices near `from` toward the drag vector (from→to).
 */
export function stretchRegion(from, to) {
  const drag = new THREE.Vector3().subVectors(to, from);
  const tmp  = new THREE.Vector3();
  const { radius, strength } = mesh.userData;
  for (let i = 0; i < vertexCount; i++) {
    tmp.fromArray(originalPos, i*3);
    const d = tmp.distanceTo(from);
    if (d > radius) continue;
    const falloff = 1 - (d/radius);
    const idx = i*3;
    positions.array[idx  ] += drag.x * strength * falloff;
    positions.array[idx+1] += drag.y * strength * falloff;
    positions.array[idx+2] += drag.z * strength * falloff;
  }
  positions.needsUpdate = true;
}

/**
 * Runs spring-damper on every vertex.
 */
export function updateSprings(dt) {
  const pos = positions.array;
  for (let i = 0; i < vertexCount; i++) {
    const idx = i*3;
    const dx = pos[idx  ] - originalPos[idx];
    const dy = pos[idx+1] - originalPos[idx+1];
    const dz = pos[idx+2] - originalPos[idx+2];
    // Hooke’s law + damping
    const fx = -mesh.userData.kStiff * dx - mesh.userData.damping * velocities[idx];
    const fy = -mesh.userData.kStiff * dy - mesh.userData.damping * velocities[idx+1];
    const fz = -mesh.userData.kStiff * dz - mesh.userData.damping * velocities[idx+2];
    velocities[idx  ] += (fx * dt);
    velocities[idx+1] += (fy * dt);
    velocities[idx+2] += (fz * dt);
    pos[idx  ] += velocities[idx  ] * dt;
    pos[idx+1] += velocities[idx+1] * dt;
    pos[idx+2] += velocities[idx+2] * dt;
  }
  positions.needsUpdate = true;
}

/**
 * Instantly snap all vertices back to original.
 */
export function resetMesh() {
  positions.array.set(originalPos);
  velocities.fill(0);
  positions.needsUpdate = true;
}
```

---

## `src/ui/controlsUI.js`

```js
import GUI from 'dat.gui';

export function initControls({ onReset, onDownload, onParamsChange }) {
  const gui = new GUI({ width: 260 });
  const params = {
    radius:   0.3,
    strength: 1.0,
    stiffness: 8,
    damping:   4,
    reset:     () => onReset(),
    download:  () => onDownload()
  };

  gui.add(params, 'radius', 0.05, 1.0).onChange(() => onParamsChange(params));
  gui.add(params, 'strength', 0.1, 5.0).onChange(() => onParamsChange(params));
  gui.add(params, 'stiffness', 1, 20).onChange(() => onParamsChange(params));
  gui.add(params, 'damping', 0, 10).onChange(() => onParamsChange(params));
  gui.add(params, 'reset');
  gui.add(params, 'download').name('Save Image');

  return gui;
}
```

---

## `src/utils/share.js`

```js
/**
 * Capture the WebGL canvas and trigger a download
 */
export function captureCanvas(canvas) {
  canvas.toBlob(blob => {
    const url = URL.createObjectURL(blob);
    const a   = document.createElement('a');
    a.href    = url;
    a.download= 'stretchy-face.png';
    a.click();
    URL.revokeObjectURL(url);
  });
}
```

---

With these in place, you have every piece wired up:

1. **`index.html`** brings in the UI and canvas.  
2. **`styles.css`** lays out the page.  
3. **`main.js`** ties together upload → detect → mesh → interact → animate.  
4. **`faceDetection.js`** does client‑side face bounding‑box.  
5. **`cropperUI.js`** handles the image‑cropper workflow.  
6. **`meshDeformer.js`** builds the deformable mesh and spring physics.  
7. **`controlsUI.js`** gives you sliders and buttons.  
8. **`share.js`** lets users save their stretched masterpiece.

You can now `npm run dev`, iterate on parameters, and when you’re ready `npm run build && npm run deploy` to Vercel. Enjoy building!